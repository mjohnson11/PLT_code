{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library                                 CLM_2N-R1-Time0\n",
      "R1_files    Stanford_mid_LT_CLM_2N-R1-Time0_R1.fastq.gz\n",
      "Name: 0, dtype: object\n",
      "@NS500615:281:H5TNGAFXX:1:11101:18943:1018 1:N:0:0 GCTAANGGGCCAATTTAATATGGACTAAAGGAGGCTTTTGTCGACGGATCCGATATCGGTACCACCATAAGCATTAACTCGTTTTGGACATAACTTCGTATAATGTATGCTATACGAAGTTATCCCCCAACCGTAAAGAATCTTGAAATGG AAAAA#EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEEEEEA6AEEEEEEEE<EEEEEEEE<\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Looks like this isn’t a strictly 4-line fastq file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2ecb5c4cbe4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0mpaired\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'001.fastq'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'R1_files'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# all the pre-demultiplexed, unpaired subpool sequencing has this format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0mbcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'R1_files'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Library'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaired\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0mbcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_lib_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_stats_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2ecb5c4cbe4f>\u001b[0m in \u001b[0;36mread_files\u001b[0;34m(self, R1_files, tmp_lib, paired)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mR2_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFourLineFastq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreads2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mR1_title\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR1_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR1_qual\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mFourLineFastq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreads1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0mrc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpaired\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/fs-desai01/srv/export/desai_lab/share/users/mjohnson/raw_sequencing_data/PLT/final_for_submission/PLT_code/processing/PLT_tools.py\u001b[0m in \u001b[0;36mFourLineFastq\u001b[0;34m(handle)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mjnk_line\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"+\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjnk_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Looks like this isn’t a strictly 4-line fastq file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mqual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Looks like this isn’t a strictly 4-line fastq file"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "A program to demultiplex reads and count barcodes for the PLT\n",
    "Milo Johnson\n",
    "Started 3_6_16\n",
    "made simple 2_6_17\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "from PLT_htmlReport import make_html_report\n",
    "from PLT_tools import FourLineFastq, reverse_transcribe\n",
    "\n",
    "\n",
    "# POSITIONAL ARGS - THESE SHOULD ALWAYS BE THE SAME FOR A RUN\n",
    "assay_number = 13\n",
    "out_base = '../../output/'\n",
    "QUALITY_CUTOFF = 30\n",
    "with open('../file_info/All_assays.txt') as infile:\n",
    "    a_list = infile.readlines()\n",
    "    run_name = a_list[assay_number].strip()\n",
    "    \n",
    "assay_file = pd.read_csv('../file_info/assay_files/'+run_name+'_assay.csv')\n",
    "output_dir = out_base + run_name + '/'\n",
    "output_file = output_dir + run_name + '_bc_counts.csv'\n",
    "stats_out_base = output_dir + 'run_statistics/'\n",
    "lib_stats_out = stats_out_base + run_name + '_library_statistics.csv'\n",
    "umi_fam_size_out = stats_out_base + run_name + '_umi_family_sizes.csv'\n",
    "html_report_out = stats_out_base + run_name + '_html_report'\n",
    "\n",
    "all_primer_info = {row['Filename']: row for j, row in pd.read_csv('../file_info/All_file_primer_info.csv').iterrows()}\n",
    "read_file_base = '../../all_reads_demultiplexed/'\n",
    "\n",
    "if not os.path.isdir(output_dir):\n",
    "    print('Making main output directory:', output_dir)\n",
    "    subprocess.call(['mkdir', output_dir])\n",
    "if not os.path.isdir(stats_out_base):\n",
    "    print('Making stats output directory:', stats_out_base)\n",
    "    subprocess.call(['mkdir', stats_out_base])\n",
    "\n",
    "MY_REGEX = re.compile('\\D*?(GTACC|GGACC|GGTCC|G.TACC|GG.ACC|GGT.CC|GGTA.C|GGTAC.)(\\D{24,28})(.TAACT|A.AACT|AT.ACT|ATA.CT|ATAA.T|ATAAC|AAACT|ATACT|ATAAT)\\D*')\n",
    "\n",
    "\n",
    "class BcCounter:\n",
    "\n",
    "    \"\"\"\n",
    "    BcCounter counts barcodes and corrects counts based on the unique molecular indices (UMIs) they are paired with.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, assay_file):\n",
    "        # this bc_dict has entries like: [bc div, bc env, total counts, [counts_in_lib_1, counts_in_lib_2, etc.]]\n",
    "        self.bc_dict = dict()\n",
    "\n",
    "        self.dem_df = assay_file\n",
    "\n",
    "        self.libraries = list(self.dem_df['Library'])\n",
    "        self.num_libraries = len(self.libraries)\n",
    "\n",
    "        # this dict has keys for each library, and entries like\n",
    "        # [total reads, failed on quality, failed on regex, failed on UMI, primer dimer likely]\n",
    "        self.lib_stats = {l: [0, 0, 0, 0, 0] for l in self.libraries}\n",
    "        self.other_reads = 0  # reads not in any of the libraries\n",
    "        # this dict has keys that are the libraries and values that are dictionaries\n",
    "        # these dictionaries have concatenated UMIs and entries that are counts in that UMI family\n",
    "        self.umi_dict = {l: dict() for l in self.libraries}\n",
    "\n",
    "    def add_count(self, bc_div, bc_env, library_index):\n",
    "        bc = bc_div + bc_env\n",
    "        if bc in self.bc_dict:\n",
    "            tmp_entry = self.bc_dict[bc]\n",
    "            tmp_entry[2] += 1\n",
    "            tmp_entry[3][library_index] += 1\n",
    "        else:\n",
    "            tmp_entry = self.bc_dict[bc] = [bc_div, bc_env, 1, [0]*self.num_libraries]\n",
    "            tmp_entry[3][library_index] += 1\n",
    "\n",
    "    def read_files(self, R1_files, tmp_lib, paired):\n",
    "        for R1in in R1_files:\n",
    "            file_info = all_primer_info[R1in]\n",
    "            dbc_start = file_info['R1_bp_to_BC']\n",
    "            if paired:\n",
    "                ebc_start = file_info['R2_bp_to_BC']\n",
    "            else:\n",
    "                ebc_start = dbc_start + 60\n",
    "            reads1 = gzip.open(read_file_base+R1in, 'rt')\n",
    "            if paired:\n",
    "                reads2 = gzip.open(read_file_base+R1in.replace('R1.fastq.gz', 'R2.fastq.gz'), 'rt')\n",
    "                R2_iterator = FourLineFastq(reads2)\n",
    "            rc = 0\n",
    "            for R1_title, R1_seq, R1_qual in FourLineFastq(reads1):\n",
    "                rc += 1\n",
    "                if paired:\n",
    "                    R2_title, R2_seq, R2_qual = next(R2_iterator)\n",
    "                else: # for unpaired sequencing (subpools) - we are filtering for inline index here\n",
    "                    # this doesn't happen for the others because they have already been demultiplexed\n",
    "                    if R1_seq[:8] != file_info['R1_index']:\n",
    "                        break\n",
    "                tmp_lib_stats = self.lib_stats[tmp_lib]\n",
    "                tmp_lib_stats[0] += 1   # count for total reads\n",
    "                # Quality check\n",
    "                if paired:\n",
    "                    qual_failed = np.mean([ord(c)-33 for c in (R1_qual[dbc_start:dbc_start+26] +\n",
    "                                                    R2_qual[ebc_start:ebc_start+26])]) < QUALITY_CUTOFF\n",
    "                else:\n",
    "                    # for the unpaired subpool sequencing, just looking on R1\n",
    "                    qual_failed = np.mean([ord(c)-33 for c in (R1_qual[dbc_start:dbc_start+26] +\n",
    "                                                    R1_qual[ebc_start:ebc_start+26])]) < QUALITY_CUTOFF\n",
    "                # quality check\n",
    "                if qual_failed:\n",
    "                    tmp_lib_stats[1] += 1\n",
    "                else:\n",
    "                    # regex check\n",
    "                    reghit1 = MY_REGEX.match(R1_seq[dbc_start-10:dbc_start+36])\n",
    "                    if paired:\n",
    "                        reghit2 = MY_REGEX.match(R2_seq[ebc_start-10:ebc_start+36])\n",
    "                    else:\n",
    "                        reghit2 = MY_REGEX.match(reverse_transcribe(R1_seq[ebc_start-10:ebc_start+36]))\n",
    "                    if (not reghit1) or (not reghit2):\n",
    "                        # regex failed\n",
    "                        tmp_lib_stats[2] += 1\n",
    "                        # checks if regex failed because this was a primer-dimer fragment\n",
    "                        if paired:\n",
    "                            primer_dimer_fail = 'TTGAATTCGA' in R1_seq\n",
    "                        else:\n",
    "                            primer_dimer_fail = 'CTGTCTCTT' in R1_seq\n",
    "                        if primer_dimer_fail:\n",
    "                            tmp_lib_stats[4] += 1\n",
    "                    else:\n",
    "                        bc_div = reghit1.group(2)\n",
    "                        bc_env = reghit2.group(2)\n",
    "                        # umi check\n",
    "                        if paired:\n",
    "                            umi_combined = R1_seq[:8] + R2_seq[:8]\n",
    "                            if umi_combined in self.umi_dict[tmp_lib]:\n",
    "                                self.umi_dict[tmp_lib][umi_combined] += 1\n",
    "                                tmp_lib_stats[3] += 1\n",
    "                            else:\n",
    "                                self.umi_dict[tmp_lib][umi_combined] = 1\n",
    "                                # all checks passed, group 2 in the regex match is the barcode region\n",
    "                                self.add_count(bc_div, bc_env, tmp_lib_ind)\n",
    "                        else: # for unpaired subpool sequencing we don't worry about UMIs\n",
    "                            self.add_count(bc_div, bc_env, tmp_lib_ind)\n",
    "\n",
    "        reads1.close()\n",
    "        if paired:\n",
    "            reads2.close()\n",
    "\n",
    "    def write_output(self, fout):\n",
    "\n",
    "        with open(fout, 'w') as outfile:\n",
    "            writer = csv.writer(outfile)\n",
    "            writer.writerow(['Diverse.BC', 'Environment.BC', 'Total.Counts'] + self.libraries)\n",
    "            sorted_bcs = sorted(self.bc_dict, key=lambda x: self.bc_dict[x][2], reverse=True)\n",
    "            for bc in sorted_bcs:\n",
    "                entry = self.bc_dict[bc]\n",
    "                writer.writerow(entry[:3]+entry[3])\n",
    "\n",
    "    def write_lib_stats(self, fout):\n",
    "\n",
    "        with open(fout, 'w') as outfile:\n",
    "            writer = csv.writer(outfile)\n",
    "            writer.writerow(['Library', 'Total.Reads', 'Quality.Failed', 'Regex.Failed', 'UMI.Repeats', 'Primer.Dimer',\n",
    "                             'Usable.Reads'])\n",
    "            for lib in self.libraries:\n",
    "                entry = self.lib_stats[lib]\n",
    "                writer.writerow([lib] + entry + [entry[0]-entry[1]-entry[2]-entry[3]])\n",
    "\n",
    "    def write_umi_fam_sizes(self, fout):\n",
    "        # outputs rows with umi family size distributions for all libraries in the run\n",
    "        biggest_fam = max([max(self.umi_dict[l].values()) for l in self.libraries if len(self.umi_dict[l]) > 0])\n",
    "        with open(fout, 'w') as outfile:\n",
    "            writer = csv.writer(outfile)\n",
    "            writer.writerow(['Library'] + [str(i) for i in range(1, biggest_fam + 1)])\n",
    "            for lib in self.libraries:\n",
    "                tmp_row = [lib]\n",
    "                lib_fam_sizes = list(self.umi_dict[lib].values())\n",
    "                tmp_row += [lib_fam_sizes.count(i) for i in range(1, biggest_fam + 1)]\n",
    "                writer.writerow(tmp_row)\n",
    "\n",
    "\n",
    "otime = time.time()\n",
    "bcc = BcCounter(assay_file)\n",
    "\n",
    "for j, row in assay_file.iterrows():\n",
    "    print(row)\n",
    "    paired = '001.fastq' in row['R1_files'] # all the pre-demultiplexed, unpaired subpool sequencing has this format\n",
    "    bcc.read_files(row['R1_files'].split(';'), row['Library'], paired)\n",
    "\n",
    "bcc.write_lib_stats(lib_stats_out)\n",
    "\n",
    "bcc.write_output(output_file)\n",
    "\n",
    "bcc.write_umi_fam_sizes(umi_fam_size_out)\n",
    "\n",
    "make_html_report(lib_stats_out, umi_fam_size_out, html_report_out, run_name)\n",
    "\n",
    "print('Time:', time.time()-otime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "milo_py37",
   "language": "python",
   "name": "milo_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
